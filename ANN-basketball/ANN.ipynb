{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Marcelino\n",
    "September 2024\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.029882Z",
     "start_time": "2024-09-21T21:46:43.025970Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/gabriel/Desktop/FALL2024/CST-435/Code/ANN-basketball', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/gabriel/Library/Python/3.11/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.113423Z",
     "start_time": "2024-09-21T21:46:43.058595Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pool = []\n",
    "training_data = []\n",
    "# create pool with players from 2019-2022\n",
    "with open('all_seasons.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    # ignore first line\n",
    "    next(csvFile)\n",
    "    for lines in csvFile:\n",
    "        year = int(lines[21][:4])\n",
    "        if 2018 < year < 2023 and len(pool) < 100 and lines[1] not in pool:\n",
    "            pool.append(lines)\n",
    "        elif len(training_data) < 5000:\n",
    "            training_data.append(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Team : Considerations\n",
    "For my optimal team, I will aim for:\n",
    "- 1 or more players in top 20% of shooting percentage.\n",
    "- Player in the top 5% out of the 100 for rebounds.\n",
    "- Player with a Defensive Rebound percentage bigger than 0.2\n",
    "- 3 or more players in top 20% of best net rating\n",
    "- 2 or more players with better than average assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.129894Z",
     "start_time": "2024-09-21T21:46:43.119710Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_optimal_team(features, average_assists, top_20_ts, top_10_reb, top_20_rating):\n",
    "        label = 0\n",
    "    # check if there are 2 players with better than average assists\n",
    "        players_ast = [player for player in features if float(player['ast']) > average_assists]\n",
    "        if len(players_ast) >= 3:\n",
    "            # check if 1 or more players in top 20% of shooting percentage\n",
    "            players_ts = [player for player in features if float(player['ts_pct']) > top_20_ts]\n",
    "            if len(players_ts) >= 1:\n",
    "                # check if any player is in the top 10% for rebounds\n",
    "                players_reb = [player for player in features if float(player['reb']) > 1]\n",
    "                if len(players_reb) >=5:\n",
    "                    # check if any player on team has dreb pct > 0.2\n",
    "                    players_dreb = [player for player in features if float(player['dreb_pct'])>0.2]\n",
    "                    if len(players_dreb) >=2:\n",
    "                        # check if 3 or more players in top 20% of net rating\n",
    "                        players_rating = [player for player in features if float(player['rating']) > top_20_rating]\n",
    "                        if len(players_rating) >= 3:\n",
    "                            # Optimal Team Found\n",
    "                            label = 1\n",
    "        return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.118428Z",
     "start_time": "2024-09-21T21:46:43.114943Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(pool):\n",
    "    features_list = []\n",
    "    for player in pool:\n",
    "        # extract relevant features based on considerations above\n",
    "        features = {\n",
    "            'name': player[1],\n",
    "            'ts_pct': player[19],\n",
    "            'reb': player[13],\n",
    "            'dreb_pct': player[17],\n",
    "            'rating': player[15],\n",
    "            'ast': player[14]\n",
    "        }\n",
    "        features_list.append(features)\n",
    "    return features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Training Data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(sample, num_iter=10000):\n",
    "    X = []\n",
    "    y = []\n",
    "    # calculate average assists\n",
    "    assists = np.array([float(player[14]) for player in sample])\n",
    "    average_assists = np.mean(assists)\n",
    "    # calculate top 20% of shooting percentage\n",
    "    top_20_ts = np.percentile([float(player[19]) for player in sample], 80)\n",
    "    # calculate top 10% of rebound\n",
    "    top_10_reb = np.percentile([float(player[13]) for player in sample], 90)\n",
    "    # calculate top 20% net rating\n",
    "    top_20_rating = np.percentile([float(player[15]) for player in sample], 80)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        # select 5 random players from list\n",
    "        selected_players = random.sample(sample, 5)\n",
    "        features = extract_features(selected_players)\n",
    "        X.append(features)\n",
    "        \"\"\"\n",
    "        - 1 or more players in top 20% of shooting percentage.\n",
    "        - Player in the top 10% for rebounds.\n",
    "        - Player with a Defensive Rebound percentage bigger than 0.2\n",
    "        - 3 or more players in top 20% of best net rating\n",
    "        - 2 or more players with better than average assists\n",
    "        \"\"\"\n",
    "        label = is_optimal_team(features, average_assists, top_20_ts, top_10_reb, top_20_rating)\n",
    "        \n",
    "        y.append(label)                   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # output shapes\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    \n",
    "    # Output number of y = 1 occurances and output\n",
    "    count_ones = np.sum(y == 1)\n",
    "    print(f\"Number of 1's in y: {count_ones}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Now that we have the training data, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:48.499861Z",
     "start_time": "2024-09-21T21:46:43.131901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10000, 5)\n",
      "Shape of y: (10000,)\n",
      "Number of 1's in y: 28\n",
      "Epoch 0, Cost: 3626.926484282593\n",
      "Epoch 100, Cost: 328.27650163102925\n",
      "Epoch 200, Cost: 190.81517448884736\n",
      "Epoch 300, Cost: 151.98975517929458\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = simulate_data(training_data)\n",
    "\n",
    "# Extract numerical features from dictionaries\n",
    "X_train = np.array([\n",
    "    [\n",
    "        float(player['ts_pct']),\n",
    "        float(player['reb']),\n",
    "        float(player['dreb_pct']),\n",
    "        float(player['rating']),\n",
    "        float(player['ast'])\n",
    "    ]\n",
    "    for team in X_train\n",
    "    for player in team\n",
    "]).reshape(len(X_train), -1)\n",
    "                    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "# Define the neural network architecture\n",
    "# Define the neural network architecture\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Compute the cost\n",
    "def compute_cost(A2, y):\n",
    "    m = y.shape[0]\n",
    "    cost = -np.sum(y * np.log(A2) + (1 - y) * np.log(1 - A2)) / m\n",
    "    return cost\n",
    "\n",
    "# Backpropagation with gradient clipping\n",
    "def backward_propagation(X, y, Z1, A1, Z2, A2):\n",
    "    m = y.shape[0]\n",
    "    dZ2 = A2 - y.reshape(-1, 1)\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_derivative(A1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Gradient clipping\n",
    "    clip_value = 1.0\n",
    "    dW1 = np.clip(dW1, -clip_value, clip_value)\n",
    "    db1 = np.clip(db1, -clip_value, clip_value)\n",
    "    dW2 = np.clip(dW2, -clip_value, clip_value)\n",
    "    db2 = np.clip(db2, -clip_value, clip_value)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Update weights and biases\n",
    "def update_parameters(dW1, db1, dW2, db2):\n",
    "    global W1, b1, W2, b2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(X_train)\n",
    "    cost = compute_cost(A2, y_train)\n",
    "    dW1, db1, dW2, db2 = backward_propagation(X_train, y_train, Z1, A1, Z2, A2)\n",
    "    update_parameters(dW1, db1, dW2, db2)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Cost: {cost}')\n",
    "\n",
    "# Evaluate the model\n",
    "_, _, _, A2_test = forward_propagation(X_test)\n",
    "y_pred = (A2_test > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain your architecture and how the basketball player characteristics are used as inputs:\n",
    "\n",
    "1. Data Preparation:\n",
    "\n",
    "- Pool and Training Data:\n",
    "    - Separates data: \n",
    "        - `pool` holds 100 unique players (2019-2022) for potential future use.\n",
    "        - `training_data` stores up to 5000 players (2019-2022) for model training.\n",
    "\n",
    "2. Feature Extraction:\n",
    "\n",
    "- The `extract_features` function takes a list of players and creates a dictionary of features for each one. \n",
    "- These features include:\n",
    "    - Name (not used as input)\n",
    "    - True Shooting Percentage (ts_pct)\n",
    "    - Rebounds (reb)\n",
    "    - Defensive Rebound Percentage (dreb_pct)\n",
    "    - Net Rating (rating)\n",
    "    - Assists (ast)\n",
    "\n",
    "3. Simulating Data for Training:\n",
    "\n",
    "- The `simulate_data` function generates training data with labels indicating successful teams based on pre-defined criteria.\n",
    "- It takes a list of players (`sample`) and a number of simulations (`num_iter`).\n",
    "- Here's how player characteristics are used as inputs:\n",
    "    - Averages and percentiles are calculated for assists, shooting percentage, rebounds, and net rating from the `sample` data.\n",
    "    - Loops through `num_iter` simulations:\n",
    "        - Selects 5 random players.\n",
    "        - Extracts their features using `extract_features`.\n",
    "        - Assigns a label (0 or 1) based on the criteria defined above..\n",
    "\n",
    "4. Model Building and Training:\n",
    "\n",
    "TO-DO\n",
    "5. Evaluation:\n",
    "\n",
    "TO-DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the output of your MLP in the context of selecting an optimal basketball team:\n",
    "\n",
    "This MLP is trained on the 'optimal' prediction, given the input features of the dataset-shooting percentage, rebounds, assists, and player ratings amongst others-a basketball lineup is optimal. These mentioned inputs provide key indications about player performance. The model will process it for a binary outcome; 1 stands for an optimum team, and 0 stands for a suboptimum team. It could be shown that the MLP model is currently trained to learn from historical data to understand whether a combination of players is strong or weak and thus provide insight into which lineups will perform likely perform.\n",
    "\n",
    "These could then inform the choice of an optimum basketball team, where the model shows which sets of players are statistically balanced in key performance metrics. The teams that are predicted as \"optimal\" will indicate that their set of players is effective, while those labeled \"suboptimal\" need adjustment. Coaches or team selectors would be able to play around with different mixes of players in order to fine-tune their strategy and ensure the team is great in a lot of aspects of the game: scoring, defense, teamwork, just to name a few.\n",
    "\n",
    "Besides the precision, recall is one of the metrics that signifies model reliability or accuracy. High accuracy means the model can discriminate between good and bad lineups well. While precision and recall give an indication of few false predictions or missing optimal teams, in the end, what an MLP model provides is a data-driven method of selection of the team so as to best ensure that the lineup chosen will perform better on the court."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
