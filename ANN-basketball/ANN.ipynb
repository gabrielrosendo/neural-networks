{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Marcelino\n",
    "September 2024\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:53:36.425771Z",
     "start_time": "2024-09-22T21:53:33.131931Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pool = []\n",
    "training_data = []\n",
    "# create pool with players from 2019-2022\n",
    "with open('all_seasons.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    # ignore first line\n",
    "    next(csvFile)\n",
    "    for lines in csvFile:\n",
    "        training_data.append(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Team : Considerations\n",
    "For my optimal team, I will aim for:\n",
    "- 1 or more players in top 20% of shooting percentage.\n",
    "- Player in the top 5% out of the 100 for rebounds.\n",
    "- Player with a Defensive Rebound percentage bigger than 0.2\n",
    "- 3 or more players in top 20% of best net rating\n",
    "- 2 or more players with better than average assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:53:36.438475Z",
     "start_time": "2024-09-22T21:53:36.434124Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(player):\n",
    "    return {\n",
    "        'name': player[1],\n",
    "        'ts_pct': float(player[19]),\n",
    "        'reb': float(player[13]),\n",
    "        'dreb_pct': float(player[17]),\n",
    "        'rating': float(player[15]),\n",
    "        'ast': float(player[14])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:53:36.433116Z",
     "start_time": "2024-09-22T21:53:36.426600Z"
    }
   },
   "outputs": [],
   "source": [
    "def team_score(team):\n",
    "    ts_pct = np.mean([player['ts_pct'] for player in team])\n",
    "    reb = np.sum([player['reb'] for player in team])\n",
    "    dreb_pct = np.max([player['dreb_pct'] for player in team])\n",
    "    rating = np.mean([player['rating'] for player in team])\n",
    "    ast = np.sum([player['ast'] for player in team])\n",
    "    # For my optimal team, the most important features are\n",
    "    # 1. True shooting percentage\n",
    "    # 2. Defensive rebound percentage\n",
    "    # 3. Rating\n",
    "    # 4. Assists/Rebounds \n",
    "    score = (ts_pct * 20 + reb * 0.5 + dreb_pct * 10 + rating + ast * 0.5) / 5\n",
    "    return score\n",
    "\n",
    "def select_optimal_team(pool, team_size=5):\n",
    "    player_features = [extract_features(player) for player in pool]\n",
    "    \n",
    "    best_team = None\n",
    "    best_score = -float('inf')\n",
    "    \n",
    "    # Use a heuristic to find a good solution\n",
    "    for _ in range(1000):  # Number of iterations\n",
    "        team = random.sample(player_features, team_size)\n",
    "        score = team_score(team)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_team = team\n",
    "    \n",
    "    return best_team, best_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Training Data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T21:53:36.445129Z",
     "start_time": "2024-09-22T21:53:36.440497Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Generate multiple pools of 100 players each and find the optimal team for each pool\n",
    "# get first and last season to get number of seasons\n",
    "num_pools = int(training_data[-1][21][:4]) - int(training_data[0][21][:4])\n",
    "num_pools = num_pools \n",
    "sample_size = 100\n",
    "all_teams = []\n",
    "all_labels = []\n",
    "\n",
    "for _ in range(num_pools):\n",
    "    pool_sample = random.sample(training_data, sample_size)\n",
    "    optimal_team, _ = select_optimal_team(pool_sample)\n",
    "    team_features = [player['ts_pct'] for player in optimal_team] + \\\n",
    "                    [player['reb'] for player in optimal_team] + \\\n",
    "                    [player['dreb_pct'] for player in optimal_team] + \\\n",
    "                    [player['rating'] for player in optimal_team] + \\\n",
    "                    [player['ast'] for player in optimal_team]\n",
    "    all_teams.append(team_features)\n",
    "    all_labels.append(1)  # Label for optimal team\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Now that we have the training data, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-22T21:53:36.446136Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 13.253689661589075\n",
      "Epoch 100, Cost: 1.2436027201619044\n",
      "Epoch 200, Cost: 0.615332510081147\n",
      "Epoch 300, Cost: 0.40628290380872933\n",
      "Epoch 400, Cost: 0.3026378479707837\n",
      "Epoch 500, Cost: 0.2408952138123665\n",
      "Epoch 600, Cost: 0.19996929177467487\n",
      "Epoch 700, Cost: 0.17087213754735603\n",
      "Epoch 800, Cost: 0.14913283988906706\n",
      "Epoch 900, Cost: 0.13227891590661628\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(all_teams)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# Normalize the features\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Compute the cost\n",
    "def compute_cost(A2, y):\n",
    "    m = y.shape[0]\n",
    "    cost = -np.sum(y * np.log(A2) + (1 - y) * np.log(1 - A2)) / m\n",
    "    return cost\n",
    "\n",
    "# Backpropagation with gradient clipping\n",
    "def backward_propagation(X, y, Z1, A1, Z2, A2):\n",
    "    m = y.shape[0]\n",
    "    dZ2 = A2 - y.reshape(-1, 1)\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_derivative(A1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Gradient clipping\n",
    "    clip_value = 1.0\n",
    "    dW1 = np.clip(dW1, -clip_value, clip_value)\n",
    "    db1 = np.clip(db1, -clip_value, clip_value)\n",
    "    dW2 = np.clip(dW2, -clip_value, clip_value)\n",
    "    db2 = np.clip(db2, -clip_value, clip_value)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Update weights and biases\n",
    "def update_parameters(dW1, db1, dW2, db2):\n",
    "    global W1, b1, W2, b2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(X_train)\n",
    "    cost = compute_cost(A2, y_train)\n",
    "    dW1, db1, dW2, db2 = backward_propagation(X_train, y_train, Z1, A1, Z2, A2)\n",
    "    update_parameters(dW1, db1, dW2, db2)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Cost: {cost}')\n",
    "\n",
    "# Evaluate the model\n",
    "_, _, _, A2_test = forward_propagation(X_test)\n",
    "y_pred = (A2_test > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain your architecture and how the basketball player characteristics are used as inputs:\n",
    "\n",
    "1. Data Preparation:\n",
    "\n",
    "- Pool and Training Data:\n",
    "    - Separates data: \n",
    "        - `pool` holds 100 unique players (2019-2022) for potential future use.\n",
    "        - `training_data` stores up to 5000 players (2019-2022) for model training.\n",
    "\n",
    "2. Feature Extraction:\n",
    "\n",
    "- The `extract_features` function takes a list of players and creates a dictionary of features for each one. \n",
    "- These features include:\n",
    "    - Name (not used as input)\n",
    "    - True Shooting Percentage (ts_pct)\n",
    "    - Rebounds (reb)\n",
    "    - Defensive Rebound Percentage (dreb_pct)\n",
    "    - Net Rating (rating)\n",
    "    - Assists (ast)\n",
    "\n",
    "3. Simulating Data for Training:\n",
    "\n",
    "- The `simulate_data` function generates training data with labels indicating successful teams based on pre-defined criteria.\n",
    "- It takes a list of players (`sample`) and a number of simulations (`num_iter`).\n",
    "- Here's how player characteristics are used as inputs:\n",
    "    - Averages and percentiles are calculated for assists, shooting percentage, rebounds, and net rating from the `sample` data.\n",
    "    - Loops through `num_iter` simulations:\n",
    "        - Selects 5 random players.\n",
    "        - Extracts their features using `extract_features`.\n",
    "        - Assigns a label (0 or 1) based on the criteria defined above..\n",
    "\n",
    "4. Model Building and Training:\n",
    "\n",
    "TO-DO\n",
    "5. Evaluation:\n",
    "\n",
    "TO-DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the output of your MLP in the context of selecting an optimal basketball team:\n",
    "\n",
    "This MLP is trained on the 'optimal' prediction, given the input features of the dataset-shooting percentage, rebounds, assists, and player ratings amongst others-a basketball lineup is optimal. These mentioned inputs provide key indications about player performance. The model will process it for a binary outcome; 1 stands for an optimum team, and 0 stands for a suboptimum team. It could be shown that the MLP model is currently trained to learn from historical data to understand whether a combination of players is strong or weak and thus provide insight into which lineups will perform likely perform.\n",
    "\n",
    "These could then inform the choice of an optimum basketball team, where the model shows which sets of players are statistically balanced in key performance metrics. The teams that are predicted as \"optimal\" will indicate that their set of players is effective, while those labeled \"suboptimal\" need adjustment. Coaches or team selectors would be able to play around with different mixes of players in order to fine-tune their strategy and ensure the team is great in a lot of aspects of the game: scoring, defense, teamwork, just to name a few.\n",
    "\n",
    "Besides the precision, recall is one of the metrics that signifies model reliability or accuracy. High accuracy means the model can discriminate between good and bad lineups well. While precision and recall give an indication of few false predictions or missing optimal teams, in the end, what an MLP model provides is a data-driven method of selection of the team so as to best ensure that the lineup chosen will perform better on the court."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
