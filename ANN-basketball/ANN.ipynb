{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Marcelino, Grant Burk, and Eli Kaustinen\n",
    "September 2024\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:41.857734Z",
     "start_time": "2024-09-22T23:07:41.853232Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/gabriel/Desktop/FALL2024/CST-435/Code/ANN-basketball', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python311.zip', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/lib-dynload', '', '/Users/gabriel/Library/Python/3.11/lib/python/site-packages', '/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:42.459938Z",
     "start_time": "2024-09-22T23:07:41.894829Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pool = []\n",
    "training_data = []\n",
    "# create pool with players from 2019-2022\n",
    "with open('all_seasons.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    # ignore first line\n",
    "    next(csvFile)\n",
    "    for lines in csvFile:\n",
    "        training_data.append(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optimal Team : Considerations\n",
    "For my optimal team, I will aim for:\n",
    "- 1 or more players in top 20% of shooting percentage.\n",
    "- Player in the top 5% out of the 100 for rebounds.\n",
    "- Player with a Defensive Rebound percentage bigger than 0.2\n",
    "- 3 or more players in top 20% of best net rating\n",
    "- 2 or more players with better than average assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:42.466025Z",
     "start_time": "2024-09-22T23:07:42.461950Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(player):\n",
    "    try:\n",
    "        return {\n",
    "            'name': player[1],\n",
    "            'ts_pct': float(player[19]),\n",
    "            'reb': float(player[13]),\n",
    "            'dreb_pct': float(player[17]),\n",
    "            'rating': float(player[15]),\n",
    "            'ast': float(player[14])\n",
    "        }\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        print(f\"Player data: {player}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:42.474636Z",
     "start_time": "2024-09-22T23:07:42.467032Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def team_score(team):\n",
    "    ts_pct = np.mean([player['ts_pct'] for player in team])\n",
    "    reb = np.sum([player['reb'] for player in team])\n",
    "    dreb_pct = np.max([player['dreb_pct'] for player in team])\n",
    "    rating = np.mean([player['rating'] for player in team])\n",
    "    ast = np.sum([player['ast'] for player in team])\n",
    "    # For my optimal team, the most important features are\n",
    "    # 1. True shooting percentage\n",
    "    # 2. Defensive rebound percentage\n",
    "    # 3. Rating\n",
    "    # 4. Assists/Rebounds\n",
    "    score = (ts_pct * 20 + reb * 0.5 + dreb_pct * 10 + rating + ast * 0.5) / 5\n",
    "    return score\n",
    "\n",
    "def select_optimal_team(pool, team_size=5):\n",
    "    player_features = [extract_features(player) for player in pool]\n",
    "    \n",
    "    best_team = None\n",
    "    best_score = -float('inf')\n",
    "\n",
    "    # Use a heuristic to find a good solution\n",
    "    for _ in range(1000):  # Number of iterations\n",
    "        team = random.sample(player_features, team_size)\n",
    "        score = team_score(team)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_team = team\n",
    "\n",
    "    return best_team, best_score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:42.481550Z",
     "start_time": "2024-09-22T23:07:42.476646Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to extract features from a player\n",
    "def extract_features(player):\n",
    "    try:\n",
    "        return {\n",
    "            'name': player[1],\n",
    "            'ts_pct': float(player[19]),\n",
    "            'reb': float(player[13]),\n",
    "            'dreb_pct': float(player[17]),\n",
    "            'rating': float(player[15]),\n",
    "            'ast': float(player[14])\n",
    "        }\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        print(f\"Player data: {player}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Simulate Training Data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T23:07:42.584202Z",
     "start_time": "2024-09-22T23:07:42.482561Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate multiple pools of 100 players each and find the optimal team for each pool\n",
    "num_pools = int(training_data[-1][21][:4]) - int(training_data[0][21][:4])\n",
    "sample_size = 100\n",
    "all_teams = []\n",
    "all_labels = []\n",
    "\n",
    "for _ in range(num_pools):\n",
    "    pool_sample = random.sample(training_data, sample_size)\n",
    "    optimal_team, _ = select_optimal_team(pool_sample)\n",
    "    if optimal_team is not None:\n",
    "        team_features = [player['ts_pct'] for player in optimal_team] + \\\n",
    "                        [player['reb'] for player in optimal_team] + \\\n",
    "                        [player['dreb_pct'] for player in optimal_team] + \\\n",
    "                        [player['rating'] for player in optimal_team] + \\\n",
    "                        [player['ast'] for player in optimal_team]\n",
    "        all_teams.append(team_features)\n",
    "        all_labels.append(1)  # Label for optimal team\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train Model\n",
    "Now that we have the training data, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-22T23:07:42.585217Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 13.25374619713537\n",
      "Epoch 100, Cost: 1.24291718759942\n",
      "Epoch 200, Cost: 0.6150262170641626\n",
      "Epoch 300, Cost: 0.40610025225946533\n",
      "Epoch 400, Cost: 0.30251392234842756\n",
      "Epoch 500, Cost: 0.24080479505645186\n",
      "Epoch 600, Cost: 0.19990019197402328\n",
      "Epoch 700, Cost: 0.17081762035089101\n",
      "Epoch 800, Cost: 0.1490888260440433\n",
      "Epoch 900, Cost: 0.1322427658192825\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(all_teams)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "# Normalize the features\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "# Define the neural network architecture\n",
    "# Define the neural network architecture\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X):\n",
    "    Z1 = np.dot(X, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# Compute the cost\n",
    "def compute_cost(A2, y):\n",
    "    m = y.shape[0]\n",
    "    cost = -np.sum(y * np.log(A2) + (1 - y) * np.log(1 - A2)) / m\n",
    "    return cost\n",
    "\n",
    "# Backpropagation with gradient clipping\n",
    "def backward_propagation(X, y, Z1, A1, Z2, A2):\n",
    "    m = y.shape[0]\n",
    "    dZ2 = A2 - y.reshape(-1, 1)\n",
    "    dW2 = np.dot(A1.T, dZ2) / m\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "    dA1 = np.dot(dZ2, W2.T)\n",
    "    dZ1 = dA1 * sigmoid_derivative(A1)\n",
    "    dW1 = np.dot(X.T, dZ1) / m\n",
    "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "    # Gradient clipping\n",
    "    clip_value = 1.0\n",
    "    dW1 = np.clip(dW1, -clip_value, clip_value)\n",
    "    db1 = np.clip(db1, -clip_value, clip_value)\n",
    "    dW2 = np.clip(dW2, -clip_value, clip_value)\n",
    "    db2 = np.clip(db2, -clip_value, clip_value)\n",
    "\n",
    "    return dW1, db1, dW2, db2\n",
    "\n",
    "# Update weights and biases\n",
    "def update_parameters(dW1, db1, dW2, db2):\n",
    "    global W1, b1, W2, b2\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    Z1, A1, Z2, A2 = forward_propagation(X_train)\n",
    "    cost = compute_cost(A2, y_train)\n",
    "    dW1, db1, dW2, db2 = backward_propagation(X_train, y_train, Z1, A1, Z2, A2)\n",
    "    update_parameters(dW1, db1, dW2, db2)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Cost: {cost}')\n",
    "\n",
    "# Evaluate the model\n",
    "_, _, _, A2_test = forward_propagation(X_test)\n",
    "y_pred = (A2_test > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Training and Evaluation\n",
    "\n",
    "\n",
    "In this section, we will train and evaluate our model using the training and testing datasets. The model is a simple neural network with one hidden layer. We will use forward propagation to compute the activations, backpropagation to compute the gradients, and gradient descent to update the weights and biases. The current accuracy is too high, which means that the model is overfitting, we are currently still looking into how to reduce overfitting. \n",
    "\n",
    "\n",
    "\n",
    "### Training Process\n",
    "\n",
    "1. **Forward Propagation**: Compute the activations for the hidden layer and the output layer.\n",
    "2. **Compute Cost**: Calculate the cost function to measure the performance of the model.\n",
    "3. **Backpropagation**: Compute the gradients of the cost function with respect to the weights and biases.\n",
    "4. **Update Parameters**: Update the weights and biases using gradient descent.\n",
    "5. **Evaluate Model**: Calculate the accuracy of the model on the testing set.\n",
    "\n",
    "The model is trained for 1000 epochs, and the cost is printed every 100 epochs. The final accuracy of the model on the testing set is also printed.\n",
    "\n",
    "This process helps in selecting an optimal basketball team by evaluating different combinations of players based on their performance metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the output of your MLP in the context of selecting an optimal basketball team:\n",
    "\n",
    "### Cost Function\n",
    "The cost function measures how well the model's predictions match the actual labels. A lower cost indicates better performance. The significant reduction in cost over epochs shows that the model is effectively learning to predict the optimal team.\n",
    "\n",
    "### Accuracy\n",
    "Achieving an accuracy of 1.0 means the model perfectly predicts whether a given team is optimal based on the features provided. This suggests that the model has learned the patterns and relationships in the data very well.\n",
    "\n",
    "### Potential Concerns\n",
    "**Overfitting**: Perfect accuracy might indicate overfitting, where the model performs exceptionally well on the training and test data but may not generalize to new, unseen data. This can be mitigated by using techniques like cross-validation, adding noise, and regularization (which has already been added).\n",
    "\n",
    "### Conclusion\n",
    "The output shows that the MLP model has effectively learned to predict the optimal basketball team based on the provided features. The significant reduction in cost and perfect accuracy indicate that the model has captured the underlying patterns in the data. However, it's essential to ensure that the model generalizes well to new data to avoid overfitting.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
