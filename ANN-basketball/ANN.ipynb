{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Marcelino\n",
    "September 2024\n",
    "Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.029882Z",
     "start_time": "2024-09-21T21:46:43.025970Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2023.3.3\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2023.3.3\\\\plugins\\\\python\\\\helpers\\\\pydev', 'C:\\\\Users\\\\grant\\\\PycharmProjects\\\\neural-networks', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', '', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\grant\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.113423Z",
     "start_time": "2024-09-21T21:46:43.058595Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "pool = []\n",
    "training_data = []\n",
    "# create pool with players from 2019-2022\n",
    "with open('all_seasons.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    # ignore first line\n",
    "    next(csvFile)\n",
    "    for lines in csvFile:\n",
    "        year = int(lines[21][:4])\n",
    "        if 2018 < year < 2023 and len(pool) < 100 and lines[1] not in pool:\n",
    "            pool.append(lines)\n",
    "        elif len(training_data) < 5000:\n",
    "            training_data.append(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Team : Considerations\n",
    "For my optimal team, I will aim for:\n",
    "- 2 or more players in top 20% of shooting percentage.\n",
    "- Player in the top 5% out of the 100 for rebounds.\n",
    "- Player with a Defensive Rebound percentage bigger than 0.2\n",
    "- 3 or more players in top 20% of best net rating\n",
    "- 2 or more players with better than average assists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.118428Z",
     "start_time": "2024-09-21T21:46:43.114943Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(pool):\n",
    "    features_list = []\n",
    "    for player in pool:\n",
    "        # extract relevant features based on considerations above\n",
    "        features = {\n",
    "            'name': player[1],\n",
    "            'ts_pct': player[19],\n",
    "            'reb': player[13],\n",
    "            'dreb_pct': player[17],\n",
    "            'rating': player[15],\n",
    "            'ast': player[14]\n",
    "        }\n",
    "        features_list.append(features)\n",
    "    return features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Training Data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:43.129894Z",
     "start_time": "2024-09-21T21:46:43.119710Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_data(sample, num_iter=10000):\n",
    "    X = []\n",
    "    y = []\n",
    "    # calculate average assists\n",
    "    assists = np.array([float(player[14]) for player in sample])\n",
    "    average_assists = np.mean(assists)\n",
    "    # calculate top 20% of shooting percentage\n",
    "    top_20_ts = np.percentile([float(player[19]) for player in sample], 80)\n",
    "    # calculate top 10% of rebound\n",
    "    top_10_reb = np.percentile([float(player[13]) for player in sample], 90)\n",
    "    # calculate top 20% net rating\n",
    "    top_20_rating = np.percentile([float(player[15]) for player in sample], 80)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        # select 5 random players from list\n",
    "        selected_players = random.sample(sample, 5)\n",
    "        features = extract_features(selected_players)\n",
    "        X.append(features)\n",
    "        \"\"\"\n",
    "        - 2 or more players in top 20% of shooting percentage.\n",
    "        - Player in the top 10% for rebounds.\n",
    "        - Player with a Defensive Rebound percentage bigger than 0.2\n",
    "        - 3 or more players in top 20% of best net rating\n",
    "        - 2 or more players with better than average assists\n",
    "        \"\"\"\n",
    "        label = 0\n",
    "        # check if there are 2 players with better than average assists\n",
    "        players_ast = [player for player in features if float(player['ast']) > average_assists]\n",
    "        if len(players_ast) >= 3:\n",
    "            # check if 2 or more players in top 20% of shooting percentage\n",
    "            players_ts = [player for player in features if float(player['ts_pct']) > top_20_ts]\n",
    "            if len(players_ts) >= 2:\n",
    "                # check if any player is in the top 10% for rebounds\n",
    "                players_reb = [player for player in features if float(player['reb']) > 1]\n",
    "                if len(players_reb) >=5:\n",
    "                    # check if any player on team has dreb pct > 0.2\n",
    "                    players_dreb = [player for player in features if float(player['dreb_pct'])>0.2]\n",
    "                    if len(players_dreb) >=2:\n",
    "                        # check if 3 or more players in top 20% of net rating\n",
    "                        players_rating = [player for player in features if float(player['rating']) > top_20_rating]\n",
    "                        if len(players_rating) >= 3:\n",
    "                            # Optimal Team Found\n",
    "                            label = 1\n",
    "        y.append(label)                   \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # output shapes\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    \n",
    "    # Output number of y = 1 occurances and output\n",
    "    count_ones = np.sum(y == 1)\n",
    "    print(f\"Number of 1's in y: {count_ones}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Now that we have the training data, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T21:46:48.499861Z",
     "start_time": "2024-09-21T21:46:43.131901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (10000, 5)\n",
      "Shape of y: (10000,)\n",
      "Number of 1's in y: 16\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8662 - loss: 0.3167\n",
      "Epoch 2/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0072\n",
      "Epoch 3/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0162\n",
      "Epoch 4/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9976 - loss: 0.0204\n",
      "Epoch 5/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0051\n",
      "Epoch 6/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0079\n",
      "Epoch 7/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0054\n",
      "Epoch 8/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0053\n",
      "Epoch 9/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9989 - loss: 0.0047\n",
      "Epoch 10/10\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9992 - loss: 0.0032\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Accuracy: 0.9978\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = simulate_data(training_data)\n",
    "\n",
    "# Extract numerical features from dictionaries\n",
    "X_train = np.array([\n",
    "    [\n",
    "        float(player['ts_pct']),\n",
    "        float(player['reb']),\n",
    "        float(player['dreb_pct']),\n",
    "        float(player['rating']),\n",
    "        float(player['ast'])\n",
    "    ]\n",
    "    for team in X_train\n",
    "    for player in team\n",
    "]).reshape(len(X_train), -1)\n",
    "                    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Getting a decimal place from the prediction function so this is an activation function to turn the decimal to binary\n",
    "for i in range(len(y_pred)):\n",
    "    if(y_pred[i] > 8):\n",
    "        y_pred[i]= 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "# Helpful metrics to understanding the predictions made by the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain your architecture and how the basketball player characteristics are used as inputs:\n",
    "\n",
    "1. Data Preparation:\n",
    "\n",
    "- Pool and Training Data:\n",
    "    - Separates data: \n",
    "        - `pool` holds 100 unique players (2019-2022) for potential future use.\n",
    "        - `training_data` stores up to 5000 players (2019-2022) for model training.\n",
    "\n",
    "2. Feature Extraction:\n",
    "\n",
    "- The `extract_features` function takes a list of players and creates a dictionary of features for each one. \n",
    "- These features include:\n",
    "    - Name (not used as input)\n",
    "    - True Shooting Percentage (ts_pct)\n",
    "    - Rebounds (reb)\n",
    "    - Defensive Rebound Percentage (dreb_pct)\n",
    "    - Net Rating (rating)\n",
    "    - Assists (ast)\n",
    "\n",
    "3. Simulating Data for Training:\n",
    "\n",
    "- The `simulate_data` function generates training data with labels indicating successful teams based on pre-defined criteria.\n",
    "- It takes a list of players (`sample`) and a number of simulations (`num_iter`).\n",
    "- Here's how player characteristics are used as inputs:\n",
    "    - Averages and percentiles are calculated for assists, shooting percentage, rebounds, and net rating from the `sample` data.\n",
    "    - Loops through `num_iter` simulations:\n",
    "        - Selects 5 random players.\n",
    "        - Extracts their features using `extract_features`.\n",
    "        - Assigns a label (0 or 1) based on these criteria:\n",
    "            - At least 2 players with above-average assists (uses extracted assist data).\n",
    "            - At least 2 players with top 20% shooting percentage (uses shooting percentage data).\n",
    "            - At least 1 player with top 10% rebounds (uses rebound data).\n",
    "            - At least 1 player with defensive rebound percentage > 0.2 (uses defensive rebound percentage data).\n",
    "            - At least 3 players with top 20% net rating (uses net rating data).\n",
    "    - This process essentially creates training examples where the input is a \"team\" of 5 players (represented by their features) and the label is 1 if it meets the criteria for a successful team.\n",
    "\n",
    "4. Model Building and Training:\n",
    "\n",
    "- Feature Extraction for Training Data:\n",
    "    - Converts the simulated teams (lists of player features) into a single NumPy array suitable for the model. \n",
    "    - This array (X_train) holds the numerical features (shooting percentage, rebounds, etc.) for each player across all simulated teams.\n",
    "- Splitting Data for Training and Testing:\n",
    "    - The code now includes `train_test_split` to separate the data into training and testing sets (X_train, X_test, y_train, y_test). This allows for evaluating model performance on unseen data.\n",
    "- Model Architecture:\n",
    "    - A Sequential Neural Network is built with Keras.\n",
    "    - It has two hidden layers with ReLU activation for non-linearity.\n",
    "    - The output layer uses sigmoid activation for binary classification (successful team or not). \n",
    "- Model Training:\n",
    "    - The model is trained on the prepared features (X_train) and labels (y_train) for 10 epochs with a batch size of 32.\n",
    "\n",
    "5. Evaluation:\n",
    "\n",
    "- The model makes predictions on the testing set (`X_test`) using `model.predict(X_test)`.\n",
    "- The predicted labels (`y_pred`) are converted to binary (0 or 1) using a threshold of 0.5 (you can adjust this value). \n",
    "- Finally, various evaluation metrics like accuracy, precision, recall, and F1-score are calculated to assess model performance on the unseen testing data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the output of your MLP in the context of selecting an optimal basketball team:\n",
    "\n",
    "This MLP is trained on the 'optimal' prediction, given the input features of the dataset-shooting percentage, rebounds, assists, and player ratings amongst others-a basketball lineup is optimal. These mentioned inputs provide key indications about player performance. The model will process it for a binary outcome; 1 stands for an optimum team, and 0 stands for a suboptimum team. It could be shown that the MLP model is currently trained to learn from historical data to understand whether a combination of players is strong or weak and thus provide insight into which lineups will perform likely perform.\n",
    "\n",
    "These could then inform the choice of an optimum basketball team, where the model shows which sets of players are statistically balanced in key performance metrics. The teams that are predicted as \"optimal\" will indicate that their set of players is effective, while those labeled \"suboptimal\" need adjustment. Coaches or team selectors would be able to play around with different mixes of players in order to fine-tune their strategy and ensure the team is great in a lot of aspects of the game: scoring, defense, teamwork, just to name a few.\n",
    "\n",
    "Besides the precision, recall is one of the metrics that signifies model reliability or accuracy. High accuracy means the model can discriminate between good and bad lineups well. While precision and recall give an indication of few false predictions or missing optimal teams, in the end, what an MLP model provides is a data-driven method of selection of the team so as to best ensure that the lineup chosen will perform better on the court."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
