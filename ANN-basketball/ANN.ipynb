{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel Marcelino, Grant Burk, and Eli Kaustinen <br>\n",
    "September 2024 <br>\n",
    "Artificial Neural Network (ANN) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "   The goal of this project is to predict the optimal basketball team composition based on player statistics. \n",
    "   The model aims to identify teams of 5 players that have the highest potential performance based on historical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "pool = []\n",
    "training_data = []\n",
    "# create pool with players from 2019-2022\n",
    "with open('all_seasons.csv', mode = 'r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    # ignore first line\n",
    "    next(csvFile)\n",
    "    for lines in csvFile:\n",
    "        year = int(lines[21][:4])\n",
    "        if 2010 < year < 2015 and len(pool) < 100 and lines[1] not in pool:\n",
    "            pool.append(lines)\n",
    "        elif len(training_data) < 5000:\n",
    "            training_data.append(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(pool):\n",
    "    features_list = []\n",
    "    for player in pool:\n",
    "        # extract relevant features based on considerations above\n",
    "        features = {\n",
    "            'name': player[1],\n",
    "            'ts_pct': player[19],\n",
    "            'reb': player[13],\n",
    "            'dreb_pct': player[17],\n",
    "            'rating': player[15],\n",
    "            'ast': player[14]\n",
    "        }\n",
    "        features_list.append(features)\n",
    "    return features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate Training Data to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_data(sample, batch_size=100):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Define the importance of each attribute (weights)\n",
    "    weights = {\n",
    "        'ast': 0.2,        # Assists\n",
    "        'ts_pct': 0.3,     # True Shooting Percentage\n",
    "        'reb': 0.25,       # Rebounds\n",
    "        'dreb_pct': 0.1,   # Defensive Rebound Percentage\n",
    "        'rating': 0.15     # Net Rating\n",
    "    }\n",
    "\n",
    "    # Define indices for each attribute in the player data\n",
    "    ts_pct_idx = 18\n",
    "    reb_idx = 12\n",
    "    dreb_pct_idx = 16\n",
    "    rating_idx = 15\n",
    "    ast_idx = 13\n",
    "    for i in range(0, len(sample), batch_size):\n",
    "        batch = sample[i:i + batch_size]\n",
    "        if len(batch) < 5:\n",
    "            continue\n",
    "\n",
    "        for j in range(0, len(batch), 5):\n",
    "            team = batch[j:j + 5]\n",
    "            if len(team) < 5:\n",
    "                continue\n",
    "\n",
    "            team_features = []\n",
    "            team_rating = 0\n",
    "            for player in team:\n",
    "                try:\n",
    "                    player_features = [\n",
    "                        float(player[ts_pct_idx]) * weights['ts_pct'],\n",
    "                        float(player[reb_idx]) * weights['reb'],\n",
    "                        float(player[dreb_pct_idx]) * weights['dreb_pct'],\n",
    "                        float(player[rating_idx]) * weights['rating'],\n",
    "                        float(player[ast_idx]) * weights['ast']\n",
    "                    ]\n",
    "                    team_features.extend(player_features)\n",
    "                    team_rating += float(player[rating_idx])\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"Error processing player data: {e}\")\n",
    "\n",
    "            X.append(team_features)\n",
    "            y.append(1 if team_rating > 0 else 0)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f\"Shape of X: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape}\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "Now that we have the training data, we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1000, 25)\n",
      "Shape of y: (1000,)\n",
      "Epoch 1/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3548 - loss: 1.1414 - val_accuracy: 0.5300 - val_loss: 0.7126 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4757 - loss: 0.8032 - val_accuracy: 0.7100 - val_loss: 0.6256 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5161 - loss: 0.7122 - val_accuracy: 0.7333 - val_loss: 0.6038 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6115 - loss: 0.6624 - val_accuracy: 0.7700 - val_loss: 0.5822 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.6424 - loss: 0.6520 - val_accuracy: 0.8267 - val_loss: 0.5698 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6789 - loss: 0.6361 - val_accuracy: 0.8567 - val_loss: 0.5455 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6330 - loss: 0.6275 - val_accuracy: 0.8667 - val_loss: 0.5155 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.6655 - loss: 0.5986 - val_accuracy: 0.9033 - val_loss: 0.4850 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.7092 - loss: 0.5554 - val_accuracy: 0.9033 - val_loss: 0.4613 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7576 - loss: 0.5004 - val_accuracy: 0.9100 - val_loss: 0.4144 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.7714 - loss: 0.4973 - val_accuracy: 0.9167 - val_loss: 0.3737 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.7970 - loss: 0.4699 - val_accuracy: 0.9200 - val_loss: 0.3330 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7900 - loss: 0.4485 - val_accuracy: 0.9267 - val_loss: 0.3020 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7844 - loss: 0.4423 - val_accuracy: 0.9233 - val_loss: 0.2754 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.3451 - val_accuracy: 0.9267 - val_loss: 0.2490 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.8624 - loss: 0.3811 - val_accuracy: 0.9333 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.8341 - loss: 0.3798 - val_accuracy: 0.9400 - val_loss: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.8536 - loss: 0.3234 - val_accuracy: 0.9433 - val_loss: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8902 - loss: 0.2771 - val_accuracy: 0.9267 - val_loss: 0.1816 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9044 - loss: 0.2459 - val_accuracy: 0.9567 - val_loss: 0.1557 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.8831 - loss: 0.2992 - val_accuracy: 0.9200 - val_loss: 0.1753 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.8847 - loss: 0.2665 - val_accuracy: 0.9500 - val_loss: 0.1529 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8949 - loss: 0.2488 - val_accuracy: 0.9300 - val_loss: 0.1624 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8859 - loss: 0.2502 - val_accuracy: 0.9433 - val_loss: 0.1338 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.9174 - loss: 0.2231 - val_accuracy: 0.9533 - val_loss: 0.1232 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9146 - loss: 0.2115 - val_accuracy: 0.9300 - val_loss: 0.1401 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9113 - loss: 0.2176 - val_accuracy: 0.9367 - val_loss: 0.1274 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.9296 - loss: 0.1927 - val_accuracy: 0.9433 - val_loss: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.8959 - loss: 0.2387 - val_accuracy: 0.9433 - val_loss: 0.1129 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9306 - loss: 0.1754 - val_accuracy: 0.9400 - val_loss: 0.1114 - learning_rate: 0.0010\n",
      "Shape of X: (20, 25)\n",
      "Shape of y: (20,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Optimal Team Found: ['Joe Johnson', 'Joel Anthony', 'Joel Przybilla', 'Johan Petro', 'John Lucas III']\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "X_train, y_train = simulate_data(training_data)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.001)\n",
    "\n",
    "# Train the model with validation data and class weights\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_val, y_val), class_weight=class_weights, callbacks=[reduce_lr])\n",
    "\n",
    "# Use data in pool for testing\n",
    "X_test, y_test = simulate_data(pool)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, np.round(y_pred))\n",
    "precision = precision_score(y_test, np.round(y_pred))\n",
    "recall = recall_score(y_test, np.round(y_pred))\n",
    "f1 = f1_score(y_test, np.round(y_pred))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Find the optimal team with the highest prediction score\n",
    "best_team_index = np.argmax(y_pred)\n",
    "best_team = pool[best_team_index*5:(best_team_index+1)*5]\n",
    "\n",
    "# Print the optimal team\n",
    "print(f\"Optimal Team Found: {[player[1] for player in best_team]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain your architecture and how the basketball player characteristics are used as inputs:\n",
    "1. Data Preparation:\n",
    "\n",
    "- Pool and Training Data:\n",
    "    - `pool`: 100 unique players (2019-2022) for testing.\n",
    "    - `training_data`: Up to 5000 players (2019-2022) for model training.\n",
    "\n",
    "2. Feature Extraction:\n",
    "\n",
    "- `extract_features` function creates a dictionary of features for each player:\n",
    "    - True Shooting Percentage (ts_pct)\n",
    "    - Rebounds (reb)\n",
    "    - Defensive Rebound Percentage (dreb_pct)\n",
    "    - Net Rating (rating)\n",
    "    - Assists (ast)\n",
    "\n",
    "3. Simulating Data for Training:\n",
    "\n",
    "- `simulate_data` function generates training data with labels indicating successful teams based on pre-defined weights.\n",
    "\n",
    "4. Model Building and Training:\n",
    "\n",
    "- Converts simulated teams into a NumPy array (X_train).\n",
    "- Splits data into training and validation sets.\n",
    "- Sequential Neural Network with Keras:\n",
    "    - Two hidden layers with ReLU activation.\n",
    "    - Output layer with sigmoid activation for binary classification.\n",
    "- Model trained for 10 epochs with a batch size of 16.\n",
    "\n",
    "5. Evaluation:\n",
    "\n",
    "- Model predictions on testing set (`X_test`).\n",
    "- Evaluation metrics: accuracy, precision, recall, and F1-score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
